{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121df493",
   "metadata": {},
   "source": [
    "# LangGraph 中的記憶體最佳化與管理\n",
    "## 為什麼需要記憶體管理?\n",
    "\n",
    "當我們建構具備記憶能力的 Agent 時，最容易忽略的就是記憶體管理的重要性。首先是 LLM 的上下文限制問題，不同模型有不同的 token 上限，例如：\n",
    "- GPT-4 從 8k 到 128k tokens\n",
    "- Claude 達 200k tokens\n",
    "\n",
    "但問題在於：Agent 是持續運行的。\n",
    "當對話與內部狀態不斷累積，很快就會觸及模型的 token 天花板，導致：\n",
    "- 對話被強制截斷\n",
    "- 模型注意力被耗散\n",
    "- token 消耗大\n",
    "- 效能降低\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534992b",
   "metadata": {},
   "source": [
    "## 記憶類型與分層概念\n",
    "\n",
    "要有效管理 Agent 的記憶，第一步是理解：\n",
    "不是所有記憶都應該被同樣對待。\n",
    "\n",
    "我們可以依「用途」與「生命週期」將記憶劃分為不同類型。\n",
    "### 1. 短期對話記憶（Short-term Conversation Memory）\n",
    "- 用途：維持當前對話的上下文連貫性\n",
    "- 生命週期：僅限於單一會話\n",
    "- 常見策略：\n",
    "    - 只保留最近幾輪\n",
    "    - 或最近 N 個 tokens\n",
    "\n",
    "這類記憶不需要永久保存，過期即丟是正常設計。\n",
    "\n",
    "### 2. 任務與目標記憶（Task / Goal Memory）\n",
    "- 記錄內容：\n",
    "    - 當前任務目標\n",
    "    - 已完成步驟\n",
    "    - 待辦事項（TODO）\n",
    "\n",
    "- 特性：與特定任務綁定\n",
    "\n",
    "當任務完成後，這類記憶可以：\n",
    "- 被歸檔\n",
    "- 或直接清除\n",
    "\n",
    "不需要長期佔用「工作記憶」。\n",
    "\n",
    "### 3. 長期使用者與知識記憶（Long-term Memory）\n",
    "這一類包括：\n",
    "- 使用者偏好\n",
    "- 累積的背景知識\n",
    "- 系統運行經驗\n",
    "\n",
    "理論上它們需要長期保存，但實務上仍必須引入衰減機制，因為：\n",
    "\n",
    "- 偏好會改變\n",
    "- 知識會過時\n",
    "- 長期未使用的記憶，價值會下降\n",
    "\n",
    "「永久保存」不等於「永久活躍」。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2abb1",
   "metadata": {},
   "source": [
    "## Active Memory 與 Archived Memory 的分層設計\n",
    "\n",
    "在實際系統中，一個常見且有效的做法是將記憶分成兩個層級。\n",
    "### 1. Active Memory（主動記憶）\n",
    "Active Memory 是系統中的熱資料（Hot Data）層,存放那些頻繁被存取、對當前任務至關重要的記憶。這類記憶通常包括最近的對話歷史、正在進行的任務狀態,以及使用者最常用到的偏好設定。由於需要在每次 Agent 推理時快速讀取，Active Memory 會保存在高效能的儲存系統中，例如記憶體資料庫或向量資料庫的高速索引區。然而，高效能意味著高成本，因此 Active Memory 的容量必須受到嚴格控制，通常只保留數千到數萬條記錄。系統會透過重要性評分、存取頻率和時效性等指標，持續評估哪些記憶應該留在這一層，一旦記憶的價值下降或長時間未被使用，就會被降級到 Archived Memory，為更重要的新記憶騰出空間。\n",
    "\n",
    "### Archived Memory（封存記憶）\n",
    "Archived Memory 是系統的冷資料（Cold Data）層，用於長期保存那些不常使用但未來可能還需要的記憶。這些記憶可能是幾週前的對話內容、已完成任務的歷史記錄，或是很少被觸發的使用者偏好。由於存取頻率低，Archived Memory 可以使用成本較低的儲存方案，例如物件儲存或壓縮後的資料庫，檢索速度雖然較慢但容量幾乎不受限制。重要的是,歸檔並不等於刪除,當 Agent 在 Active Memory 中找不到相關資訊時，仍然可以向 Archived Memory 發起查詢，如果發現某條歸檔記憶突然變得重要(例如使用者提到很久以前的話題)，系統可以將其重新啟動並提升回 Active Memory。這種動態的分層機制讓 Agent 既能保持快速反應，又能在需要時調用深層的歷史記憶，就像人類大腦在日常思考時主要依賴短期記憶，但在特定情境下也能喚醒塵封已久的往事。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ee470",
   "metadata": {},
   "source": [
    "## 對話上下文壓縮與裁切\n",
    "### Trimming：限制對話歷史長度\n",
    "\n",
    "**固定窗口：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d52a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_window_trim(messages, max_count=10):\n",
    "    \"\"\"保留最近 N 條訊息\"\"\"\n",
    "    return messages[-max_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9574283",
   "metadata": {},
   "source": [
    "**滑動窗口：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d53770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_trim(messages, max_tokens=4000):\n",
    "    \"\"\"基於 token 數量的滑動窗口\"\"\"\n",
    "    total_tokens = 0\n",
    "    trimmed = []\n",
    "\n",
    "    for msg in reversed(messages):\n",
    "        msg_tokens = count_tokens(msg)\n",
    "        if total_tokens + msg_tokens > max_tokens:\n",
    "            break\n",
    "        trimmed.insert(0, msg)\n",
    "        total_tokens += msg_tokens\n",
    "\n",
    "    return trimmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88f4fa",
   "metadata": {},
   "source": [
    "**在 LangGraph 中的 reducer 實作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a58a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing import Annotated\n",
    "\n",
    "def trim_messages_reducer(existing, new):\n",
    "    \"\"\"自動裁切訊息的 reducer\"\"\"\n",
    "    all_messages = existing + new\n",
    "    return sliding_window_trim(all_messages, max_tokens=4000)\n",
    "\n",
    "class TrimmedState(MessagesState):\n",
    "    messages: Annotated[list, trim_messages_reducer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cff377",
   "metadata": {},
   "source": [
    "### Summarization：壓縮舊對話\n",
    "\n",
    "**摘要時機**\n",
    "\n",
    "- Token 數達閾值(如 80% 上限)\n",
    "- 每 N 輪對話\n",
    "- 任務階段切換時\n",
    "\n",
    "**分段摘要**\n",
    "\n",
    "- 把完整對話 切成固定大小的區塊\n",
    "\n",
    "- 每一段獨立摘要\n",
    "\n",
    "- 最後得到的是「摘要列表（list of summaries）」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "messages = [m1, m2, m3, ..., m60]\n",
    "   ↓ \n",
    "Segment 1 = [m1  ~ m20]\n",
    "Segment 2 = [m21 ~ m40]\n",
    "Segment 3 = [m41 ~ m60]\n",
    "   ↓ \n",
    "Summary_1 = summarize(Segment 1)\n",
    "Summary_2 = summarize(Segment 2)\n",
    "Summary_3 = summarize(Segment 3)\n",
    "   ↓ \n",
    "summaries = [\n",
    "  Summary_1,\n",
    "  Summary_2,\n",
    "  Summary_3\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分段摘要:每段獨立總結\n",
    "def segment_summarize(messages, segment_size=20):\n",
    "    summaries = []\n",
    "    for i in range(0, len(messages), segment_size):\n",
    "        segment = messages[i:i+segment_size]\n",
    "        segment_text = \"\\n\".join([m.content for m in segment])  # 確保是純文字\n",
    "        summary = llm.summarize(segment_text)\n",
    "        summaries.append(summary)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4768b86",
   "metadata": {},
   "source": [
    "**累積摘要**\n",
    "\n",
    "- 永遠只有 一份「當前總結」\n",
    "\n",
    "- 每來新對話，就在舊摘要基礎上滾動更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary₀\n",
    "   ↓ + messages₁\n",
    "Summary₁\n",
    "   ↓ + messages₂\n",
    "Summary₂\n",
    "   ↓ + messages₃\n",
    "Summary₃\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd625836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 累積摘要:滾動更新總結\n",
    "def rolling_summarize(current_summary, new_messages):\n",
    "    # 將 messages 轉成文字\n",
    "    new_text = \"\\n\".join([m.content for m in new_messages])\n",
    "    prompt = f\"現有摘要:\\n{current_summary}\\n\\n新對話:\\n{new_text}\\n\\n更新摘要:\"\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247ada5",
   "metadata": {},
   "source": [
    "**Summarization Node 設計**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_node(state: dict):\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    total_tokens = count_tokens(\"\\n\".join([m.content for m in messages]))\n",
    "    \n",
    "    if total_tokens > THRESHOLD:\n",
    "        # 保留最近 10 條\n",
    "        old_messages = messages[:-10]\n",
    "        old_text = \"\\n\".join([m.content for m in old_messages])\n",
    "        summary = llm.summarize(old_text)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [SystemMessage(content=summary)] + messages[-10:],\n",
    "            \"summary_count\": state.get(\"summary_count\", 0) + 1\n",
    "        }\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db657c7f",
   "metadata": {},
   "source": [
    "## 記憶價值與生命週期管理\n",
    "\n",
    "### 記憶生命週期概念\n",
    "\n",
    "建立 → 使用 → 強化 / 衰減 → 淘汰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de8c62",
   "metadata": {},
   "source": [
    "### 記憶評分與 Metadata 設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e972fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, content: str, tags=None):\n",
    "        if tags is None:\n",
    "            tags = []\n",
    "        self.content = content\n",
    "        self.metadata = {\n",
    "            \"importance\": 0.5,        # 記憶的重要性分數 (0~1)\n",
    "            \"recency\": time.time(),    # 最近一次被使用或命中的時間\n",
    "            \"access_count\": 0,         # 被存取或引用的次數\n",
    "            \"created_at\": time.time(), # 建立時間\n",
    "            \"tags\": tags               # 主題或語意標籤\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a11b3",
   "metadata": {},
   "source": [
    "**重要性計算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_importance(memory):\n",
    "    keywords = [\"目標\", \"錯誤\", \"決策\", \"使用者偏好\"]\n",
    "    keyword_hits = sum(1 for kw in keywords if kw in memory.content)\n",
    "    keyword_score = min(keyword_hits * 0.2, 1.0)  # 保證不超過 1\n",
    "\n",
    "    # LLM 評估\n",
    "    llm_score = llm.evaluate_importance(memory.content)  # 0-1\n",
    "\n",
    "    return min(keyword_score + llm_score, 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096deca",
   "metadata": {},
   "source": [
    "### 記憶衰減機制\n",
    "**時間衰減**\n",
    "\n",
    "- 長時間未被使用的記憶，即使曾經重要，也會逐漸失效\n",
    "\n",
    "- 模擬人類對「過時資訊」的自然遺忘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f11972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_decay(memory, decay_rate=0.01):\n",
    "    \"\"\"每天衰減 1%\"\"\"\n",
    "    days_elapsed = (now() - memory.metadata[\"created_at\"]).days\n",
    "    return (1 - decay_rate) ** days_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13ecd9",
   "metadata": {},
   "source": [
    "**使用頻率衰減**\n",
    "\n",
    "- 反覆被使用 = 真正有價值\n",
    "\n",
    "- 防止重要但較舊的記憶被時間衰減過度削弱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_boost(memory):\n",
    "    \"\"\"存取次數越多越重要\"\"\"\n",
    "    access_count = memory.metadata[\"access_count\"]\n",
    "    boost = min(math.log(access_count + 1) * 0.1, 0.5)\n",
    "    return 1.0 + boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b460158",
   "metadata": {},
   "source": [
    "**最近性因素**\n",
    "- 強化當前上下文相關性\n",
    "- 提供短期動態權重以補足長期評分模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recency_boost(memory, half_life_days=7):\n",
    "    \"\"\"最近存取的記憶獲得加成\"\"\"\n",
    "    days_since_access = (now() - memory.metadata[\"recency\"]).days\n",
    "\n",
    "    recency_factor = 2 ** (-days_since_access / half_life_days)\n",
    "\n",
    "    if days_since_access == 0:\n",
    "        recency_factor = 1.5\n",
    "\n",
    "    return recency_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210759c",
   "metadata": {},
   "source": [
    "**混合衰減策略**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef58551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_decay(memory):\n",
    "    \"\"\"\n",
    "    混合記憶衰減策略\n",
    "    - 時間衰減：避免舊記憶永久佔據高權重\n",
    "    - 使用頻率：反覆被用的記憶更有價值\n",
    "    - 最近性：短期上下文相關性補償\n",
    "    \"\"\"\n",
    "\n",
    "    # 原始重要度（0 ~ 1）\n",
    "    base_importance = memory.metadata[\"importance\"]\n",
    "\n",
    "    # 各種影響因子（皆為倍率）\n",
    "    time_factor = time_decay(memory)          # < 1\n",
    "    freq_factor = frequency_boost(memory)     # >= 1\n",
    "    recency_factor = recency_boost(memory)    # >= 0\n",
    "\n",
    "    # 混合計算\n",
    "    final_score = (\n",
    "        base_importance\n",
    "        * time_factor\n",
    "        * freq_factor\n",
    "        * recency_factor\n",
    "    )\n",
    "\n",
    "    # 限制在合理範圍\n",
    "    memory.metadata[\"importance\"] = max(\n",
    "        0.0,\n",
    "        min(final_score, 1.0)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a0ef7",
   "metadata": {},
   "source": [
    "### 定期清理低價值記憶\n",
    "**閾值策略**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112254d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_memories(memories, threshold=0.2):\n",
    "    \"\"\"刪除重要性低於閾值的記憶\"\"\"\n",
    "    cleaned = []\n",
    "    for m in memories:\n",
    "        importance = m.metadata.get(\"importance\", 0)\n",
    "        if importance >= threshold:\n",
    "            cleaned.append(m)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fde32",
   "metadata": {},
   "source": [
    "**批次清理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cleanup(memory_store, batch_size=1000, threshold=0.2):\n",
    "    \"\"\"分批清理，避免阻塞，避免修改長度造成錯亂\"\"\"\n",
    "    new_store = []\n",
    "\n",
    "    for i in range(0, len(memory_store), batch_size):\n",
    "        batch = memory_store[i:i + batch_size]\n",
    "\n",
    "        # 更新衰減\n",
    "        for memory in batch:\n",
    "            hybrid_decay(memory)\n",
    "\n",
    "        # 清理後加入新列表\n",
    "        cleaned_batch = protected_cleanup(batch, threshold)\n",
    "        new_store.extend(cleaned_batch)\n",
    "\n",
    "    return new_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0bc39",
   "metadata": {},
   "source": [
    "**防止重要記憶誤刪**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c927bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protected_cleanup(memories, threshold=0.2):\n",
    "    protected_tags = {\"user_preference\", \"critical_error\", \"goal\"}\n",
    "    cleaned = []\n",
    "\n",
    "    for m in memories:\n",
    "        tags = set(m.metadata.get(\"tags\", []))\n",
    "        importance = m.metadata.get(\"importance\", 0)\n",
    "\n",
    "        # 有保護標記直接保留\n",
    "        if tags & protected_tags:\n",
    "            cleaned.append(m)\n",
    "        # 或重要性足夠\n",
    "        elif importance >= threshold:\n",
    "            cleaned.append(m)\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322e57f",
   "metadata": {},
   "source": [
    "## 記憶結構最佳化\n",
    "\n",
    "### 記憶合併 (Memory Consolidation)\n",
    "**核心概念**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "當一筆新記憶進來時\n",
    "→ 找出是否存在「語意相似」的舊記憶\n",
    "→ 若相似度足夠高，則依策略合併，而非直接新增\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8501d39",
   "metadata": {},
   "source": [
    "\n",
    "**相似度判斷**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_memories(\n",
    "    new_memory: Memory,\n",
    "    existing_memories: List[Memory],\n",
    "    threshold: float = 0.85\n",
    "):\n",
    "    similar = []\n",
    "\n",
    "    for mem in existing_memories:\n",
    "        similarity = cosine_similarity(\n",
    "            [new_memory.embedding],\n",
    "            [mem.embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        if similarity >= threshold:\n",
    "            similar.append((mem, similarity))\n",
    "\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63877278",
   "metadata": {},
   "source": [
    "**合併策略**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23593e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_memories(memories: List[Memory], strategy=\"summarize\") -> Memory:\n",
    "    if strategy == \"replace\":\n",
    "        return max(memories, key=lambda m: m.metadata.get(\"importance\", 0.5))\n",
    "\n",
    "    if strategy == \"merge\":\n",
    "        merged_content = \"\\n\".join(m.content for m in memories)\n",
    "        return create_memory(\n",
    "            merged_content,\n",
    "            importance=max(m.metadata.get(\"importance\", 0.5) for m in memories)\n",
    "        )\n",
    "\n",
    "    if strategy == \"summarize\":\n",
    "        text = \"\\n\".join(f\"- {m.content}\" for m in memories)\n",
    "        prompt = f\"請將以下多筆記憶合併成一則精簡且不遺失重點的記憶：\\n{text}\"\n",
    "\n",
    "        summary = llm.invoke(prompt).content\n",
    "\n",
    "        return create_memory(\n",
    "            summary,\n",
    "            importance=max(m.metadata.get(\"importance\", 0.5) for m in memories)\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Unknown merge strategy: {strategy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb77426",
   "metadata": {},
   "source": [
    "## 動態歸檔與分層存儲設計\n",
    "\n",
    "- Active Memory：高價值、高頻率、低延遲\n",
    "- Archive Memory：低頻使用、低成本、可再啟動\n",
    "\n",
    "**何時從 Active 移到 Archive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def should_archive(memory, now=None):\n",
    "    now = now or datetime.now(timezone.utc)\n",
    "    meta = memory.metadata\n",
    "\n",
    "    criteria = [\n",
    "        meta.get(\"importance\", 0) < 0.3,\n",
    "        (now - meta.get(\"last_accessed\", now)).days > 30,\n",
    "        meta.get(\"access_count\", 0) < 2\n",
    "    ]\n",
    "\n",
    "    return sum(criteria) >= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aae6d0",
   "metadata": {},
   "source": [
    "**歸檔後的檢索策略**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9644373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_archive(query, active_store, archive_store):\n",
    "    active_results = active_store.similarity_search_with_score(query, k=5)\n",
    "\n",
    "    if (\n",
    "        len(active_results) < 3\n",
    "        or max(score for _, score in active_results) < 0.7\n",
    "    ):\n",
    "        archive_results = archive_store.similarity_search_with_score(query, k=3)\n",
    "\n",
    "        reactivated = []\n",
    "        for mem, score in archive_results:\n",
    "            if score > 0.8:\n",
    "                reactivate_memory(mem, active_store, archive_store)\n",
    "                reactivated.append(mem)\n",
    "\n",
    "        return [m for m, _ in active_results] + reactivated\n",
    "\n",
    "    return [m for m, _ in active_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dcf793",
   "metadata": {},
   "source": [
    "**LangGraph 中的實作模式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_management_node(state: MemoryState):\n",
    "    active = state[\"active_memories\"]\n",
    "    archived = state[\"archived_memories\"]\n",
    "\n",
    "    # 衰減\n",
    "    for mem in active:\n",
    "        hybrid_decay(mem)\n",
    "\n",
    "    archive_flags = {id(m): should_archive(m) for m in active}\n",
    "\n",
    "    to_archive = [m for m in active if archive_flags[id(m)]]\n",
    "    active = [m for m in active if not archive_flags[id(m)]]\n",
    "\n",
    "    archived.extend(to_archive)\n",
    "\n",
    "    active = consolidate_memories(active)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"active_memories\": active,\n",
    "        \"archived_memories\": archived,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
