{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121df493",
   "metadata": {},
   "source": [
    "# LangGraph 中的記憶體最佳化與管理\n",
    "## 為什麼需要記憶體管理?\n",
    "\n",
    "當我們建構具備記憶能力的 Agent 時，最容易忽略的就是記憶體管理的重要性。首先是 LLM 的上下文限制問題，不同模型有不同的 token 上限，例如：\n",
    "- GPT-4 從 8k 到 128k tokens\n",
    "- Claude 達 200k tokens\n",
    "\n",
    "但問題在於：Agent 是持續運行的。\n",
    "當對話與內部狀態不斷累積，很快就會觸及模型的 token 天花板，導致：\n",
    "- 對話被強制截斷\n",
    "- 模型注意力被耗散\n",
    "- token 消耗大\n",
    "- 效能降低\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534992b",
   "metadata": {},
   "source": [
    "## 記憶類型與生命週期概覽\n",
    "\n",
    "要有效管理 Agent 的記憶，第一步是理解：\n",
    "不是所有記憶都應該被同樣對待。\n",
    "\n",
    "我們可以依「用途」與「生命週期」將記憶劃分為不同類型。\n",
    "### 1. 短期對話記憶（Short-term Conversation Memory）\n",
    "- 用途：維持當前對話的上下文連貫性\n",
    "- 生命週期：僅限於單一會話\n",
    "- 常見策略：\n",
    "    - 只保留最近幾輪\n",
    "    - 或最近 N 個 tokens\n",
    "\n",
    "這類記憶不需要永久保存，過期即丟是正常設計。\n",
    "\n",
    "### 2. 任務與目標記憶（Task / Goal Memory）\n",
    "- 記錄內容：\n",
    "    - 當前任務目標\n",
    "    - 已完成步驟\n",
    "    - 待辦事項（TODO）\n",
    "\n",
    "- 特性：與特定任務綁定\n",
    "\n",
    "當任務完成後，這類記憶可以：\n",
    "- 被歸檔\n",
    "- 或直接清除\n",
    "\n",
    "不需要長期佔用「工作記憶」。\n",
    "\n",
    "### 3. 長期使用者與知識記憶（Long-term Memory）\n",
    "這一類包括：\n",
    "- 使用者偏好\n",
    "- 累積的背景知識\n",
    "- 系統運行經驗\n",
    "\n",
    "理論上它們需要長期保存，但實務上仍必須引入衰減機制，因為：\n",
    "\n",
    "- 偏好會改變\n",
    "- 知識會過時\n",
    "- 長期未使用的記憶，價值會下降\n",
    "\n",
    "「永久保存」不等於「永久活躍」。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2abb1",
   "metadata": {},
   "source": [
    "## Active Memory 與 Archived Memory 的分層設計\n",
    "\n",
    "在實際系統中，一個常見且有效的做法是將記憶分成兩個層級。\n",
    "### 1. Active Memory（主動記憶）\n",
    "Active Memory 是系統中的熱資料（Hot Data）層,存放那些頻繁被存取、對當前任務至關重要的記憶。這類記憶通常包括最近的對話歷史、正在進行的任務狀態,以及使用者最常用到的偏好設定。由於需要在每次 Agent 推理時快速讀取，Active Memory 會保存在高效能的儲存系統中，例如記憶體資料庫或向量資料庫的高速索引區。然而，高效能意味著高成本，因此 Active Memory 的容量必須受到嚴格控制，通常只保留數千到數萬條記錄。系統會透過重要性評分、存取頻率和時效性等指標，持續評估哪些記憶應該留在這一層，一旦記憶的價值下降或長時間未被使用，就會被降級到 Archived Memory，為更重要的新記憶騰出空間。\n",
    "\n",
    "### Archived Memory（封存記憶）\n",
    "Archived Memory 是系統的冷資料（Cold Data）層，用於長期保存那些不常使用但未來可能還需要的記憶。這些記憶可能是幾週前的對話內容、已完成任務的歷史記錄，或是很少被觸發的使用者偏好。由於存取頻率低，Archived Memory 可以使用成本較低的儲存方案，例如物件儲存或壓縮後的資料庫，檢索速度雖然較慢但容量幾乎不受限制。重要的是,歸檔並不等於刪除,當 Agent 在 Active Memory 中找不到相關資訊時，仍然可以向 Archived Memory 發起查詢，如果發現某條歸檔記憶突然變得重要(例如使用者提到很久以前的話題)，系統可以將其重新啟動並提升回 Active Memory。這種動態的分層機制讓 Agent 既能保持快速反應，又能在需要時調用深層的歷史記憶，就像人類大腦在日常思考時主要依賴短期記憶，但在特定情境下也能喚醒塵封已久的往事。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ee470",
   "metadata": {},
   "source": [
    "## 對話上下文壓縮與裁切\n",
    "### Trimming：限制對話歷史長度\n",
    "\n",
    "**固定窗口：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d52a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_window_trim(messages, max_count=10):\n",
    "    \"\"\"保留最近 N 條訊息\"\"\"\n",
    "    return messages[-max_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9574283",
   "metadata": {},
   "source": [
    "**滑動窗口：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d53770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_trim(messages, max_tokens=4000):\n",
    "    \"\"\"基於 token 數量的滑動窗口\"\"\"\n",
    "    total_tokens = 0\n",
    "    trimmed = []\n",
    "    \n",
    "    for msg in reversed(messages):\n",
    "        msg_tokens = count_tokens(msg)\n",
    "        if total_tokens + msg_tokens > max_tokens:\n",
    "            break\n",
    "        trimmed.insert(0, msg)\n",
    "        total_tokens += msg_tokens\n",
    "    \n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88f4fa",
   "metadata": {},
   "source": [
    "**在 LangGraph 中的 reducer 實作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a58a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing import Annotated\n",
    "\n",
    "def trim_messages_reducer(existing, new):\n",
    "    \"\"\"自動裁切訊息的 reducer\"\"\"\n",
    "    all_messages = existing + new\n",
    "    return sliding_window_trim(all_messages, max_tokens=4000)\n",
    "\n",
    "class TrimmedState(MessagesState):\n",
    "    messages: Annotated[list, trim_messages_reducer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be04ec",
   "metadata": {},
   "source": [
    "### to be continued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
